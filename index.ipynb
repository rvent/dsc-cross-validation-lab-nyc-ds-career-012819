{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = reg.predict(X_train)\n",
    "y_hat_test = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_residuals = y_train - y_hat_train\n",
    "X_test_residuals = y_test - y_hat_test\n",
    "X_train_MSE = mean_squared_error(y_train, y_hat_train)\n",
    "X_test_MSE = mean_squared_error(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.731064107766134"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers\n",
    "    df = pd.DataFrame(data)\n",
    "    d_lst = []\n",
    "    samp = 0\n",
    "    count = 0\n",
    "    k  = k+1\n",
    "    last = 0\n",
    "    if len(data) % k == 0:\n",
    "        while count <= k+1:\n",
    "            d_lst.append(df.iloc[lambda x: (x.index >= samp) & (x.index <= (samp+int(len(data)/k)-1))])\n",
    "            samp += int(len(data)/k)\n",
    "            count +=1\n",
    "    else:\n",
    "        while count <= (k - (len(data) % k) + 1):\n",
    "            d_lst.append(df.iloc[lambda x: (x.index >= samp) & (x.index <= samp+int(len(data)/k)-1)])\n",
    "            samp += int(len(data)//k)\n",
    "            count +=1\n",
    "            last = samp+int(len(data)/k)-1\n",
    "        d_lst.append(df.iloc[lambda x: (x.index >  last) & (x.index <= int(len(data))-1)])\n",
    "    return d_lst #folds should be a list of subsets of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CHAS     RM       DIS         B     LSTAT     0  target\n",
      "499   0.0  5.569  0.317486  0.997151  0.572599  17.5    17.5\n",
      "500   0.0  6.027  0.334399  1.000000  0.485410  16.8    16.8\n",
      "501   0.0  6.593  0.331081  0.987619 -0.169811  22.4    22.4\n",
      "502   0.0  6.120  0.297277  1.000000 -0.274682  20.6    20.6\n",
      "503   0.0  6.976  0.274575  1.000000 -1.067939  23.9    23.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.645772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.147565</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.895</td>\n",
       "      <td>0.675609</td>\n",
       "      <td>0.994730</td>\n",
       "      <td>-0.023142</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.610606</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>-0.382682</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.985</td>\n",
       "      <td>0.610606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.157795</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.968</td>\n",
       "      <td>0.610606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.236594</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS     RM       DIS         B     LSTAT     0  target\n",
       "336   0.0  5.869  0.645772  1.000000 -0.147565  19.5    19.5\n",
       "337   0.0  5.895  0.675609  0.994730 -0.023142  18.5    18.5\n",
       "338   0.0  6.059  0.610606  0.998084 -0.382682  20.6    20.6\n",
       "339   0.0  5.985  0.610606  1.000000 -0.157795  19.0    19.0\n",
       "340   0.0  5.968  0.610606  1.000000 -0.236594  18.7    18.7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to concatenate the data again\n",
    "data = pd.merge(X, y, on=X.index)\n",
    "data[\"target\"] = data[0]\n",
    "data = data.drop('key_0', axis=1)\n",
    "folds = kfolds(data, k=5)\n",
    "print(folds[5].tail())\n",
    "folds[4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.021437184446516, 23.346908726358503, 20.230582873154006, 20.652325176385006, 12.721515124341654]\n",
      "[14.01931833988997, 11.01679923502021, 28.989972983030672, 28.357156773453404, 87.18398323109275]\n"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = pd.concat([fold for i, fold in enumerate(folds) if i!=n])\n",
    "    test = folds[n]\n",
    "    # Fit a linear regression model\n",
    "    reg = LinearRegression().fit(train[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']], \n",
    "                                 train[\"target\"])\n",
    "    #Evaluate Train and Test Errors\n",
    "    y_hat_train = reg.predict(train[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']])\n",
    "    y_hat_test = reg.predict(test[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']])\n",
    "    train_residuals = y_hat_train - train[\"target\"]\n",
    "    test_residuals = y_hat_test - test[\"target\"]\n",
    "    train_errs.append(np.mean(train_residuals**2))\n",
    "    test_errs.append(np.mean(test_residuals**2))\n",
    "\n",
    "print(train_errs)\n",
    "print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.40514492, -17.4440168 , -37.03271139, -58.27954385,\n",
       "       -26.09798876])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = cross_val_score(reg, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "cv_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
